[
  {
    "version": "0.1.4",
    "title": "Phoenix Initial Public Release",
    "date": "2025-08-02",
    "notes": "The first release of Phoenix, a local-first chat interface supporting both offline and online LLMs. Phoenix includes a built-in interactive chat UI for immediate use. Alternatively, users can connect to language models via API or socket interfaces, whether running locally or hosted remotely. This version also features voice-to-text and text-to-speech modules, and supports direct chat with PDF documents. The system is developer-friendly and can operate fully offline after setup when using local models.",
    "features": [
      "Support for both offline (local) and online (API/socket) language models",
      "Integrated chat UI with real-time interaction",
      "Prompt editor with multi-line and template support",
      "Conversation history viewer",
      "Model configuration panel (select model, device, temperature, etc.)",
      "Voice-to-text (speech recognition) and text-to-speech synthesis",
      "Chat with PDF files using embedded document reader",
      "Basic plugin system for model providers",
      "Socket and API server support for both local and remote models",
      "Works completely offline after setup (for local models)"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.5",
    "title": "Phoenix Initial Public Release",
    "date": "2025-08-04",
    "notes": "The first release of Phoenix, a local-first chat interface supporting both offline and online LLMs. Phoenix includes a built-in interactive chat UI for immediate use. Alternatively, users can connect to language models via API or socket interfaces, whether running locally or hosted remotely. This version also features voice-to-text and text-to-speech modules, and supports direct chat with PDF documents. The system is developer-friendly and can operate fully offline after setup when using local models.",
    "features": [
      "Support for both offline (local) and online (API/socket) language models",
      "Integrated chat UI with real-time interaction",
      "Prompt editor with multi-line and template support",
      "Conversation history viewer",
      "Model configuration panel (select model, device, temperature, etc.)",
      "Voice-to-text (speech recognition) and text-to-speech synthesis",
      "Chat with PDF files using embedded document reader",
      "Basic plugin system for model providers",
      "Socket and API server support for both local and remote models",
      "Works completely offline after setup (for local models)"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.7",
    "title": "Phoenix Initial Public Release",
    "date": "2025-09-19",
    "notes": "Phoenix is an open-source application built with Qt/QML that enables seamless interaction with Large Language Models (LLMs) locally, without requiring an internet connection. The platform is designed to automatically detect whether your system has a GPU and load models accordingly, allowing you to use them as powerful AI assistants directly on your machine.",
    "features": [
      "Support for both offline (local) and online (API/socket) language models",
      "Integrated chat UI with real-time interaction",
      "Prompt editor with multi-line and template support",
      "Conversation history viewer",
      "Model configuration panel (select model, device, temperature, etc.)",
      "Voice-to-text (speech recognition) and text-to-speech synthesis",
      "Chat with PDF files using embedded document reader",
      "Basic plugin system for model providers",
      "Socket and API server support for both local and remote models",
      "Works completely offline after setup (for local models)"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.8",
    "title": "Phoenix Initial Public Release",
    "date": "2025-09-20",
    "notes": "Phoenix is an open-source application built with Qt/QML that enables seamless interaction with Large Language Models (LLMs) locally, without requiring an internet connection. The platform is designed to automatically detect whether your system has a GPU and load models accordingly, allowing you to use them as powerful AI assistants directly on your machine.",
    "features": [
      "Support for both local and online models, as well as all models available on Hugging Face.",
      "Integrated speech-to-text functionality using local models, enabling real-time voice recording and transcription.",
      "Flexible integration through API or socket connections, so that other applications on your system can access and use the locally loaded models.",
      "Full customization of model configurations, giving users control to adapt performance and resources to their specific needs.",
      "A clean and user-friendly UI that simplifies interaction with models and settings"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.10",
    "title": "Phoenix Public Release",
    "date": "2025-09-23",
    "notes": "Phoenix is an open-source application built with Qt/QML that enables seamless interaction with Large Language Models (LLMs) locally, without requiring an internet connection. The platform is designed to automatically detect whether your system has a GPU and load models accordingly, allowing you to use them as powerful AI assistants directly on your machine.",
    "features": [
      "Support for both local and online models, as well as all models available on Hugging Face.",
      "Integrated speech-to-text functionality using local models, enabling real-time voice recording and transcription.",
      "Flexible integration through API or socket connections, so that other applications on your system can access and use the locally loaded models.",
      "Full customization of model configurations, giving users control to adapt performance and resources to their specific needs.",
      "A clean and user-friendly UI that simplifies interaction with models and settings"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.30",
    "title": "Phoenix Update — IndoxRouter Integration and Enhanced Online Models",
    "date": "2025-10-10",
    "notes": "This update introduces full integration with IndoxRouter models, expanding Phoenix’s ability to connect with powerful online and hybrid AI engines. Several issues affecting model loading and interaction from the previous release have been resolved. In addition, this version brings broader support for online models, improved reliability, and smoother performance across all components.",
    "features": [
      "Added full support for IndoxRouter models with optimized routing and communication handling.",
      "Fixed multiple bugs related to model initialization and response management from the previous version.",
      "Introduced more online models with enhanced stability and faster connection times.",
      "Improved overall system reliability and performance during multi-model operation.",
      "Updated internal APIs to ensure better compatibility with future model expansions."
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.32",
    "title": "Local Model Fixes & Google Suggestions Integration",
    "date": "2025-10-16",
    "notes": "This version fixes issues with local model loading and performance, and integrates Google suggestions into Phoenix. System reliability during multi-model operation has also been improved.",
    "features": [
      "Fixed local model bugs and improved response handling",
      "Added Google suggestions for enhanced model interaction",
      "Improved system stability and performance during multi-model operation",
      "Updated internal APIs for better future compatibility"
    ],
    "support": "phoenix@osllm.ai"
  }
]
