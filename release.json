[
  {
    "version": "0.1.4",
    "title": "Phoenix Initial Public Release",
    "date": "2025-08-02",
    "notes": "The first release of Phoenix, a local-first chat interface supporting both offline and online LLMs. Phoenix includes a built-in interactive chat UI for immediate use. Alternatively, users can connect to language models via API or socket interfaces, whether running locally or hosted remotely. This version also features voice-to-text and text-to-speech modules, and supports direct chat with PDF documents. The system is developer-friendly and can operate fully offline after setup when using local models.",
    "features": [
      "Support for both offline (local) and online (API/socket) language models",
      "Integrated chat UI with real-time interaction",
      "Prompt editor with multi-line and template support",
      "Conversation history viewer",
      "Model configuration panel (select model, device, temperature, etc.)",
      "Voice-to-text (speech recognition) and text-to-speech synthesis",
      "Chat with PDF files using embedded document reader",
      "Basic plugin system for model providers",
      "Socket and API server support for both local and remote models",
      "Works completely offline after setup (for local models)"
    ],
    "support": "support@nemati.ai"
  },
  {
    "version": "0.1.5",
    "title": "Phoenix Initial Public Release",
    "date": "2025-08-04",
    "notes": "The first release of Phoenix, a local-first chat interface supporting both offline and online LLMs. Phoenix includes a built-in interactive chat UI for immediate use. Alternatively, users can connect to language models via API or socket interfaces, whether running locally or hosted remotely. This version also features voice-to-text and text-to-speech modules, and supports direct chat with PDF documents. The system is developer-friendly and can operate fully offline after setup when using local models.",
    "features": [
      "Support for both offline (local) and online (API/socket) language models",
      "Integrated chat UI with real-time interaction",
      "Prompt editor with multi-line and template support",
      "Conversation history viewer",
      "Model configuration panel (select model, device, temperature, etc.)",
      "Voice-to-text (speech recognition) and text-to-speech synthesis",
      "Chat with PDF files using embedded document reader",
      "Basic plugin system for model providers",
      "Socket and API server support for both local and remote models",
      "Works completely offline after setup (for local models)"
    ],
    "support": "support@nemati.ai"
  },
  {
    "version": "0.1.7",
    "title": "Phoenix Initial Public Release",
    "date": "2025-09-19",
    "notes": "Phoenix is an open-source application built with Qt/QML that enables seamless interaction with Large Language Models (LLMs) locally, without requiring an internet connection. The platform is designed to automatically detect whether your system has a GPU and load models accordingly, allowing you to use them as powerful AI assistants directly on your machine.",
    "features": [
      "Support for both offline (local) and online (API/socket) language models",
      "Integrated chat UI with real-time interaction",
      "Prompt editor with multi-line and template support",
      "Conversation history viewer",
      "Model configuration panel (select model, device, temperature, etc.)",
      "Voice-to-text (speech recognition) and text-to-speech synthesis",
      "Chat with PDF files using embedded document reader",
      "Basic plugin system for model providers",
      "Socket and API server support for both local and remote models",
      "Works completely offline after setup (for local models)"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.8",
    "title": "Phoenix Initial Public Release",
    "date": "2025-09-20",
    "notes": "Phoenix is an open-source application built with Qt/QML that enables seamless interaction with Large Language Models (LLMs) locally, without requiring an internet connection. The platform is designed to automatically detect whether your system has a GPU and load models accordingly, allowing you to use them as powerful AI assistants directly on your machine.",
    "features": [
      "Support for both local and online models, as well as all models available on Hugging Face.",
      "Integrated speech-to-text functionality using local models, enabling real-time voice recording and transcription.",
      "Flexible integration through API or socket connections, so that other applications on your system can access and use the locally loaded models.",
      "Full customization of model configurations, giving users control to adapt performance and resources to their specific needs.",
      "A clean and user-friendly UI that simplifies interaction with models and settings"
    ],
    "support": "phoenix@osllm.ai"
  },
  {
    "version": "0.1.9",
    "title": "Phoenix Public Release",
    "date": "2025-09-21",
    "notes": "Phoenix is an open-source application built with Qt/QML that enables seamless interaction with Large Language Models (LLMs) locally, without requiring an internet connection. The platform is designed to automatically detect whether your system has a GPU and load models accordingly, allowing you to use them as powerful AI assistants directly on your machine.",
    "features": [
      "Support for both local and online models, as well as all models available on Hugging Face.",
      "Integrated speech-to-text functionality using local models, enabling real-time voice recording and transcription.",
      "Flexible integration through API or socket connections, so that other applications on your system can access and use the locally loaded models.",
      "Full customization of model configurations, giving users control to adapt performance and resources to their specific needs.",
      "A clean and user-friendly UI that simplifies interaction with models and settings"
    ],
    "support": "phoenix@osllm.ai"
  }
]
