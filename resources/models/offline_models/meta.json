[
  {
    "order": "a",
    "md5sum": "c87ad09e1e4c8f9c35a5fcef52b6f1c9",
    "modelName": "Meta-Llama-3-8B-Instruct.Q4_0",
    "name": "Llama 3 8B Instruct",
    "filename": "Meta-Llama-3-8B-Instruct.Q4_0.gguf",
    "filesize": 4.66,
    "requires": "2.7.1",
    "ramrequired": 8,
    "parameters": "8 billion",
    "recommended": true,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "description": "<ul><li>Fast responses</li><li>Chat based model</li><li>Accepts system prompts in Llama 3 format</li><li>Trained by Meta</li><li>License: <a href=\"https://llama.meta.com/llama3/license/\">Meta Llama 3 Community License</a></li></ul>",
    "url": "https://gpt4all.io/models/gguf/Meta-Llama-3-8B-Instruct.Q4_0.gguf",
    "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>"
  },
  {
    "order": "d",
    "md5sum": "8a9c75bcd8a66b7693f158ec96924eeb",
    "modelName": "Meta-Llama-3.1-8B-Instruct-128k-Q4_0",
    "name": "Llama 3.1 8B Instruct 128k",
    "filename": "Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf",
    "filesize": 4.66,
    "requires": "3.1.1",
    "ramrequired": 8,
    "parameters": "8 billion",
    "recommended": true,
    "quant": "q4_0",
    "type": "Text Generation",
    "description": "<ul><li><strong>For advanced users only. Not recommended for use on Windows or Linux without selecting CUDA due to speed issues.</strong></li><li>Fast responses</li><li>Chat based model</li><li>Large context size of 128k</li><li>Accepts agentic system prompts in Llama 3.1 format</li><li>Trained by Meta</li><li>License: <a href=\"https://llama.meta.com/llama3_1/license/\">Meta Llama 3.1 Community License</a></li></ul>",
    "url": "https://huggingface.co/GPT4All-Community/Meta-Llama-3.1-8B-Instruct-128k/resolve/main/Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf",
    "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2",
    "systemPrompt": "<|start_header_id|>system<|end_header_id|>\nCutting Knowledge Date: December 2023\n\nYou are a helpful assistant.<|eot_id|>"
  },
  {
    "order": "g",
    "md5sum": "00c8593ba57f5240f59662367b3ed4a5",
    "modelName": "orca-2-7b.Q4_0",
    "name": "Orca 2 (Medium)",
    "filename": "orca-2-7b.Q4_0.gguf",
    "filesize": 3.82,
    "requires": "2.5.2",
    "ramrequired": 8,
    "parameters": "7 billion",
    "recommended": false,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "description": "<ul><li>Instruction based</li><li>Trained by Microsoft</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/orca-2-7b.Q4_0.gguf"
  },
  {
    "order": "h",
    "md5sum": "3c0d63c4689b9af7baa82469a6f51a19",
    "modelName": "orca-2-13b.Q4_0",
    "name": "Orca 2 (Full)",
    "filename": "orca-2-13b.Q4_0.gguf",
    "filesize": 7.36,
    "requires": "2.5.2",
    "ramrequired": 16,
    "parameters": "13 billion",
    "recommended": false,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "description": "<ul><li>Instruction based</li><li>Trained by Microsoft</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/orca-2-13b.Q4_0.gguf"
  },
  {
    "order": "i",
    "md5sum": "5aff90007499bce5c64b1c0760c0b186",
    "modelName": "wizardlm-13b-v1.2.Q4_0",
    "name": "Wizard v1.2",
    "filename": "wizardlm-13b-v1.2.Q4_0.gguf",
    "filesize": 7.36,
    "requires": "2.5.0",
    "ramrequired": 16,
    "parameters": "13 billion",
    "recommended": true,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "description": "<strong>Strong overall larger model</strong><br><ul><li>Instruction based</li><li>Gives very long responses</li><li>Finetuned with only 1k of high-quality data</li><li>Trained by Microsoft and Peking University</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/wizardlm-13b-v1.2.Q4_0.gguf"
  },
  {
    "order": "k",
    "md5sum": "3d12810391d04d1153b692626c0c6e16",
    "modelName": "nous-hermes-llama2-13b.Q4_0",
    "name": "Hermes",
    "filename": "nous-hermes-llama2-13b.Q4_0.gguf",
    "filesize": 7.36,
    "requires": "2.5.0",
    "ramrequired": 16,
    "parameters": "13 billion",
    "recommended": true,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "description": "<strong>Extremely good model</strong><br><ul><li>Instruction based</li><li>Gives long responses</li><li>Curated with 300,000 uncensored instructions</li><li>Trained by Nous Research</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/nous-hermes-llama2-13b.Q4_0.gguf",
    "promptTemplate": "### Instruction:\n%1\n\n### Response:\n"
  },
  {
    "order": "l",
    "md5sum": "40388eb2f8d16bb5d08c96fdfaac6b2c",
    "modelName": "gpt4all-13b-snoozy-q4_0",
    "name": "Snoozy",
    "filename": "gpt4all-13b-snoozy-q4_0.gguf",
    "filesize": 7.36,
    "requires": "2.5.0",
    "ramrequired": 16,
    "parameters": "13 billion",
    "recommended": false,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "description": "<strong>Very good overall model</strong><br><ul><li>Instruction based</li><li>Based on the same dataset as Groovy</li><li>Slower than Groovy, with higher quality responses</li><li>Trained by Nomic AI</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/gpt4all-13b-snoozy-q4_0.gguf"
  },
  {
    "order": "p",
    "md5sum": "0e769317b90ac30d6e09486d61fefa26",
    "modelName": "orca-mini-3b-gguf2-q4_0",
    "name": "Mini Orca (Small)",
    "filename": "orca-mini-3b-gguf2-q4_0.gguf",
    "filesize": 1.97,
    "requires": "2.5.0",
    "ramrequired": 4,
    "parameters": "3 billion",
    "recommended": false,
    "quant": "q4_0",
    "type": "Text Generation",
    "description": "<strong>Small version of new model with novel dataset</strong><br><ul><li>Very fast responses</li><li>Instruction based</li><li>Explain tuned datasets</li><li>Orca Research Paper dataset construction approaches</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/orca-mini-3b-gguf2-q4_0.gguf",
    "promptTemplate": "### User:\n%1\n\n### Response:\n",
    "systemPrompt": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n\n"
  },
  {
    "order": "s",
    "md5sum": "e973dd26f0ffa6e46783feaea8f08c83",
    "disableGUI": true,
    "modelName": "rift-coder-v0-7b-q4_0",
    "name": "Rift coder",
    "filename": "rift-coder-v0-7b-q4_0.gguf",
    "filesize": 3.82,
    "requires": "2.5.0",
    "ramrequired": 8,
    "parameters": "7 billion",
    "recommended": false,
    "quant": "q4_0",
    "type": "Text Generation",
    "systemPrompt": "",
    "promptTemplate": "%1",
    "description": "<strong>Trained on collection of Python and TypeScript</strong><br><ul><li>Code completion based</li><li>WARNING: Not available for chat GUI</li></ul>",
    "url": "https://gpt4all.io/models/gguf/rift-coder-v0-7b-q4_0.gguf"
  }
]