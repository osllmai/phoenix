[
  {
    "order": "a",
    "md5sum": "",
    "name": "Whisper Base",
    "filename": "ggml-base.bin",
    "filesize": 0.142,
    "requires": "",
    "ramrequired": 1.024,
    "parameters": "74 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Standard FP32 version of the Whisper base model</li><li>Good general-purpose accuracy for various transcription tasks</li><li>Requires more memory but offers higher precision</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-base.bin"
  },
  {
    "order": "b",
    "md5sum": "",
    "name": "Whisper Base q5_1",
    "filename": "ggml-base-q5_1.bin",
    "filesize": 0.058,
    "requires": "",
    "ramrequired": 0.512,
    "parameters": "74 million",
    "quant": "q5_1",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version of Whisper base using q5_1 scheme</li><li>Significantly lower memory usage with minor drop in accuracy</li><li>Faster inference and suitable for resource-constrained environments</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-base-q5_1.bin"
  },
  {
    "order": "c",
    "md5sum": "",
    "name": "Whisper Base q8_0",
    "filename": "ggml-base-q8_0.bin",
    "filesize": 0.078,
    "requires": "",
    "ramrequired": 0.768,
    "parameters": "74 million",
    "quant": "q8_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version of Whisper base using q8_0 (8-bit weights)</li><li>Balances accuracy and memory efficiency well</li><li>Higher precision among quantized variants</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-base-q8_0.bin"
  },
  {
    "order": "d",
    "md5sum": "",
    "name": "Whisper Base En",
    "filename": "ggml-base.en.bin",
    "filesize": 0.142,
    "requires": "",
    "ramrequired": 1.024,
    "parameters": "74 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>English-only version of the Whisper base model</li><li>Smaller vocabulary and faster performance for English input</li><li>Improved accuracy for English speech</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-base.en.bin"
  },
  {
    "order": "e",
    "md5sum": "",
    "name": "Whisper Base En q5_1",
    "filename": "ggml-base.en-q5_1.bin",
    "filesize": 0.050,
    "requires": "",
    "ramrequired": 0.512,
    "parameters": "74 million",
    "quant": "q5_1",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized English-only base model using q5_1 method</li><li>Reduced memory usage and faster performance</li><li>Ideal for real-time English transcription on limited hardware</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-base.en-q5_1.bin"
  },
  {
    "order": "f",
    "md5sum": "",
    "name": "Whisper Base En q8_0",
    "filename": "ggml-base.en-q8_0.bin",
    "filesize": 0.078,
    "requires": "",
    "ramrequired": 0.768,
    "parameters": "74 million",
    "quant": "q8_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>High-precision quantized version of English-only base model</li><li>Excellent balance of accuracy and performance</li><li>Faster than FP32 with minimal accuracy loss for English input</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-base.en-q8_0.bin"
  },
  {
    "order": "g",
    "md5sum": "",
    "name": "Whisper Medium",
    "filename": "ggml-medium.bin",
    "filesize": 1.420,
    "requires": "",
    "ramrequired": 5.000,
    "parameters": "769 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Medium-sized Whisper model with higher transcription accuracy</li><li>Full-precision (FP32) version</li><li>Suitable for use cases where memory and performance are not limited</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-medium.bin"
  },
  {
    "order": "h",
    "md5sum": "",
    "name": "Whisper Medium q5_0",
    "filename": "ggml-medium-q5_0.bin",
    "filesize": 0.540,
    "requires": "",
    "ramrequired": 2.200,
    "parameters": "769 million",
    "quant": "q5_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version of the medium Whisper model using q5_0</li><li>Significantly reduced memory usage with good accuracy</li><li>Recommended for medium-accuracy tasks on limited hardware</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-medium-q5_0.bin"
  },
  {
    "order": "i",
    "md5sum": "",
    "name": "Whisper Medium q8_0",
    "filename": "ggml-medium-q8_0.bin",
    "filesize": 0.870,
    "requires": "",
    "ramrequired": 3.000,
    "parameters": "769 million",
    "quant": "q8_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version of Whisper Medium using q8_0 (higher precision)</li><li>Great balance between quality and runtime speed</li><li>Recommended for multilingual use cases with decent hardware</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-medium-q8_0.bin"
  },
  {
    "order": "j",
    "md5sum": "",
    "name": "Whisper Medium En q5_0",
    "filename": "ggml-medium.en-q5_0.bin",
    "filesize": 0.510,
    "requires": "",
    "ramrequired": 2.000,
    "parameters": "769 million",
    "quant": "q5_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>English-only version of the Medium model with q5_0 quantization</li><li>Faster inference and reduced memory usage</li><li>Ideal for English transcription tasks with resource constraints</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-medium.en-q5_0.bin"
  },
  {
    "order": "k",
    "md5sum": "",
    "name": "Whisper Medium En q8_0",
    "filename": "ggml-medium.en-q8_0.bin",
    "filesize": 0.830,
    "requires": "",
    "ramrequired": 2.800,
    "parameters": "769 million",
    "quant": "q8_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>English-only version of the Medium Whisper model using q8_0 quantization</li><li>Optimized for high transcription accuracy in English</li><li>Balanced memory usage and precision</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-medium.en-q8_0.bin"
  },
  {
    "order": "l",
    "md5sum": "",
    "name": "Whisper Large v1",
    "filename": "ggml-large-v1.bin",
    "filesize": 2.950,
    "requires": "",
    "ramrequired": 10.500,
    "parameters": "1550 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>First large-scale version of Whisper with full precision (FP32)</li><li>Delivers high transcription accuracy across many languages</li><li>Best suited for systems with ample memory and compute</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v1.bin"
  },
  {
    "order": "m",
    "md5sum": "",
    "name": "Whisper Large v2",
    "filename": "ggml-large-v2.bin",
    "filesize": 2.970,
    "requires": "",
    "ramrequired": 10.500,
    "parameters": "1550 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Second and improved version of Whisper Large model</li><li>Higher accuracy in multilingual transcription tasks</li><li>Best suited for high-performance systems</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v2.bin"
  },
  {
    "order": "n",
    "md5sum": "",
    "name": "Whisper Large v2 q5_0",
    "filename": "ggml-large-v2-q5_0.bin",
    "filesize": 1.180,
    "requires": "",
    "ramrequired": 5.400,
    "parameters": "1550 million",
    "quant": "q5_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version (q5_0) of Whisper Large v2</li><li>Significantly reduced memory usage</li><li>Maintains reasonable transcription accuracy</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v2-q5_0.bin"
  },
  {
    "order": "o",
    "md5sum": "",
    "name": "Whisper Large v2 q8_0",
    "filename": "ggml-large-v2-q8_0.bin",
    "filesize": 1.980,
    "requires": "",
    "ramrequired": 7.200,
    "parameters": "1550 million",
    "quant": "q8_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version (q8_0) of Whisper Large v2</li><li>Best quality among quantized models</li><li>Still more memory-efficient than full fp32</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v2-q8_0.bin"
  },
  {
    "order": "p",
    "md5sum": "",
    "name": "Whisper Large v3",
    "filename": "ggml-large-v3.bin",
    "filesize": 2.980,
    "requires": "",
    "ramrequired": 10.500,
    "parameters": "1550 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Third and latest version of the Whisper Large model</li><li>Improved multilingual accuracy and robustness</li><li>Recommended for highest quality speech recognition</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v3.bin"
  },
  {
    "order": "q",
    "md5sum": "",
    "name": "Whisper Large v3 Turbo",
    "filename": "ggml-large-v3-turbo.bin",
    "filesize": 2.480,
    "requires": "",
    "ramrequired": 9.600,
    "parameters": "1550 million",
    "quant": "fp32",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Turbo-optimized version of Whisper Large v3</li><li>Designed for real-time transcription with lower latency</li><li>Retains high accuracy of v3 while improving speed</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v3-turbo.bin"
  },
  {
    "order": "r",
    "md5sum": "",
    "name": "Whisper Large v3 Turbo q5_0",
    "filename": "ggml-large-v3-turbo-q5_0.bin",
    "filesize": 1.540,
    "requires": "",
    "ramrequired": 5.800,
    "parameters": "1550 million",
    "quant": "q5_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Quantized version (q5_0) of Whisper Large v3 Turbo</li><li>Faster and lighter for real-time use</li><li>Great balance of speed, memory usage, and accuracy</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v3-turbo-q5_0.bin"
  },
  {
    "order": "s",
    "md5sum": "",
    "name": "Whisper Large v3 Turbo q8_0",
    "filename": "ggml-large-v3-turbo-q8_0.bin",
    "filesize": 2.480,
    "requires": "",
    "ramrequired": 9.600,
    "parameters": "1550 million",
    "quant": "q8_0",
    "company": "OpenAI",
    "type": "Speech",
    "systemPrompt": "",
    "promptTemplate": "",
    "description": "<ul><li>Turbo large-v3 model with q8_0 quantization for best speed and quality</li><li>Optimized for real-time transcription with high accuracy</li></ul>",
    "url": "https://huggingface.co/osllmai-community/whisper.cpp/resolve/main/ggml-large-v3-turbo-q8_0.bin"
  }
]